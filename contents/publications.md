#### Published

**1. [TransPrune: Token Transition Pruning for Efficient Large Vision-Language Model](https://arxiv.org/abs/2507.20630)** (CVPR 2026)

***Ao Li***, Yuxiang Duan, Jinghui Zhang, Congbo Ma, Yutong Xie, Gustavo Carneiro, Mohammad Yaqub, Hu Wang
![transprune](static/assets/img/transprune.png)

**2. [MVP: Modeling Variants of Prompts for Vision-Language Models](https://arxiv.org/abs/2503.08229)** (ICASSP 2026) 

***Ao Li***, Zongfang Liu, Xinhua Li, Jinghui Zhang, Pengwei Wang, Hu Wang
![mvp](static/assets/img/mvp.png)

**3. [EmoVerse: Enhancing Multimodal Large Language Models for Affective Computing via Multitask Learning](https://www.sciencedirect.com/science/article/pii/S0925231225014821)** (Neurocomputing)

***Ao Li***, Longwei Xu, Chen Ling, Jinghui Zhang, Pengwei Wang
![emoverse](static/assets/img/emoverse.png)

**4. [From Individuals to Crowds: Dual-Level Public Response Prediction in Social Media](https://dl.acm.org/doi/pdf/10.1145/3746027.3754828)** (ACM MM 2025)

Jinghui Zhang, Kaiyang Wan, Longwei Xu, ***Ao Li***, Zongfang Liu, Xiuying Chen
![mm](static/assets/img/mm.png)

#### Preprint

**1. [Video-XL-Pro: Reconstructive Token Compression for Extremely Long Video Understanding](https://arxiv.org/abs/2503.18478)** (Github Star 600+)

Xiangrui Liu, Yan Shu, Zheng Liu, ***Ao Li***, Yang Tian, Bo Zhao
![videoxl-pro](static/assets/img/videoxl-pro.png)

**2. [M3MAD-Bench: Are Multi-Agent Debates Really Effective Across Domains and Modalities?](https://arxiv.org/html/2601.02854v1)** (under review)

***Ao Li***, Jinghui Zhang, Luyu Li, Yuxiang Duan, Lang Gao, Mingcai Chen, Weijun Qin, Shaopeng Li, Fengxian Ji, Ning Liu, Lizhen Cui, Xiuying Chen, Yuntao Du
![m3mad-bench](static/assets/img/m3mad-bench.png)

**3. [GridPrune: From" Where to Look" to" What to Select" in Visual Token Pruning for MLLMs](https://arxiv.org/abs/2511.10081)** (under review)

Yuxiang Duan, ***Ao Li***, Yingqin Li, Luyu Li, Pengwei Wang
![gridprune](static/assets/img/gridprune.png)
